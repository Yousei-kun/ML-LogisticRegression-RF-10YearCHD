# -*- coding: utf-8 -*-
"""submission_ml_terapan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dEh5HlUw68YMbfjLJu4t7t3jXmU8iADi

# Identitas & Definisi Hasil Pekerjaan
## Ivan Budianto

### shinsuketenma0603@gmail.com
### Submission Machine Learning Terapan

## Prediksi Penderita Penyakit Jantung Berdasarkan Statistik Kesehatan 

### Metode:
- Logistic Regression
- Random Forest

Melakukan import library yang dibutuhkan (Pandas, Sci-Kit Learn, Seaborn)
"""

import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor

from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import log_loss

import seaborn as sns

"""# Pre-Processing

## Berikut adalah langkah-langkah yang saya lakukan dalam proses preprocessing data:
1. Memasukkan dataset kedalam dataframe dari file csv
2. Menandai *numerical features* dari data untuk mempermudah proses scaling menggunakan standard scaler
3. Melakukan drop di kolom education, karena kolom tersebut memiliki bobot yang kecil pada hasil akhir data, dan membuat fokus model berkurang.
4. Mengisi missing value dengan median. Missing value akan membuat data tersebut tidak dapat digunakan, dan sangat sayang untuk membuang informasi penting pada banyak row hanya karena 1-2 missing value, maka dilakukan pengisian missing value. Pengisian data dengan menggunakan median akan membantu "menetralkan" data yang hilang, karena pengisian median tidak akan menggeser atau menambah varians dari data.
5. Melakukan pemisahan antara dataset latihan (train) dan 
dataset test (test) dengan pembagian:
  - 75% dataset latihan (train set)
  - 25% dataset pengujian (test set)
6. Scaling dengan Standard Scaler sklearn. Penggunaan Standard Scaler akan membuat fitur numerik dari data dapat diproses dengan lebih mudah oleh mesin untuk modelling.

## Memasukkan dataset & menandai num features
Memasukkan dataset kedalam dataframe dari file csv
"""

#memasukkan dataset kedalam dataframe

df = pd.read_csv('framingham.csv')
numerical_features = ['cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']
df

"""## Drop column 'education'
Melakukan drop di kolom education, karena kolom tersebut memiliki bobot yang kecil pada hasil akhir data, dan membuat fokus model berkurang.
"""

#menghapus kolom education

df = df.drop('education',axis='columns')

"""## Mengecek nilai NaN (1)
Melakukan pengecekan pada setiap kolom dalam dataset untuk mencari nilai kosong (NaN)

"""

#NaN check

for i in df.columns:
    print (i+": "+str(df[i].isna().sum()))

"""## Mengisi missing value
Mengisi missing value dengan median. Missing value akan membuat data tersebut tidak dapat digunakan, dan sangat sayang untuk membuang informasi penting pada banyak row hanya karena 1-2 missing value, maka dilakukan pengisian missing value. Pengisian data dengan menggunakan median akan membantu "menetralkan" data yang hilang, karena pengisian median tidak akan menggeser atau menambah varians dari data.
"""

#Mengisi nilai kosong pada dataset dengan median dari kolom tersebut

df['cigsPerDay'] = df['cigsPerDay'].fillna(df['cigsPerDay'].median())
df['BPMeds'] = df['BPMeds'].fillna(df['BPMeds'].median())
df['totChol'] = df['totChol'].fillna(df['totChol'].median())
df['BMI'] = df['BMI'].fillna(df['BMI'].median())
df['glucose'] = df['glucose'].fillna(df['glucose'].median())
df['heartRate'] = df['heartRate'].fillna(df['heartRate'].median())

"""## Mengecek nilai NaN (2)
Melakukan pengecekan kembali pada setiap kolom dalam dataset untuk mencari nilai kosong (NaN)
"""

#melakukan pengecekan pada setiap kolom dalam dataset untuk mencari nilai kosong (NaN) setelah dilakukan preprocessing

for i in df.columns:
    print (i+": "+str(df[i].isna().sum()))

df.describe()

"""## Mendefinisikan X dan y
Mendefinisikan X dan y, dimana:
- X merupakan data yang menjadi tolok ukur untuk prediksi (data dari dataset)
- y merupakan hasil atau tujuan dari hasil prediksinya 
"""

#mendefinisikan x dan y

X = df.drop('TenYearCHD',axis='columns')
y = df['TenYearCHD']

"""## Split train & test set, standard scaling.

Melakukan pemisahkan antara dataset latihan (train) dan 
dataset test (test) dengan pembagian:
- 75% dataset latihan (train set)
- 25% dataset pengujian (test set)

Lalu, dilanjutkan dengan melakukan standard scaling untuk data-data numerik.
Scaling dilakukan dengan Standard Scaler sklearn. Penggunaan Standard Scaler akan membuat fitur numerik dari data dapat diproses dengan lebih mudah oleh mesin untuk modelling.
"""

# pemisahan dataset, dan scaling.

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)

scaler_train = StandardScaler()
scaler_train.fit(X_train[numerical_features])
X_train[numerical_features] = scaler_train.transform(X_train.loc[:, numerical_features])

scaler_test = StandardScaler()
scaler_test.fit(X_test[numerical_features])
X_test[numerical_features] = scaler_train.transform(X_test.loc[:, numerical_features])

"""# Modelling

Pembuatan model menggunakan 2 metode, yaitu:
- Logistic Regression<br>
Regresi logistik (kadang disebut model logistik atau model logit), dalam statistika digunakan untuk prediksi probabilitas kejadian suatu peristiwa dengan mencocokkan data pada fungsi logit kurva logistik. Metode ini merupakan model linier umum yang digunakan untuk regresi binomial. 

- Random Forest<br>
Metode Random Forest  merupakan salah satu metode dalam Decision Tree. Decision Tree atau pohon pengambil keputusan adalah sebuah diagram alir yang berbentuk seperti pohon yang memiliki sebuah root node yang digunakan untuk mengumpulkan data, Sebuah inner node yang berada pada root node yang berisi tentang pertanyaan tentang data dan  sebuah leaf node yang digunakan untuk memecahkan masalah serta membuat keputusan.

Penggunaan Model<br>
Berdasarkan testing tersebut, maka dapat dilihat bahwa akurasi dari model Logistic Regression memiliki akurasi yang jauh lebih tinggi dibandingkan dengan Random Forest. Maka dari itu, model yang dipilih adalah Logistic Regression.

## Mendefinisikan model & parameter yang digunakan
Mendefinisikan model, dan metode yang digunakan, yaitu Logistic Regression & Random Forest.
"""

#mendefinisikan model dan metode 
model_logRes = LogisticRegression(max_iter=1000)
model_RF = RandomForestRegressor(n_estimators=1000, max_depth=16, random_state=55, n_jobs=1)

"""## Melakukan proses training pada kedua model
Melakukan proses training (fitting) pada kedua model menggunakan dataset yang sama, yaitu dataset training. Keduanya menggunakan syntax yang sama, yaitu fit.
"""

#melakukan fitting model menggunakan dataset train pada 2 model
model_logRes.fit(X_train,y_train)
model_RF.fit(X_train, y_train)

"""## Proses testing model
Melakukan testing pada test set berupa prediksi data pada dataset test, lalu menampilkan hasilnya berupa akurasi model untuk menentukan penggunaan model.
"""

#melakukan prediksi data pada dataset test, lalu menampilkan hasilnya

y_pred_logRes = model_logRes.predict(X_test)
y_pred_RF = model_RF.predict(X_test)

print("Akurasi model Logistic Regression: {}".format(model_logRes.score(X_test,y_test).round(3)))
print("Akurasi model Random Forest\t: {}".format(model_RF.score(X_test,y_test).round(3)))

"""## Hasil model test
Berdasarkan testing tersebut, maka dapat dilihat bahwa akurasi dari model Logistic Regression memiliki akurasi yang jauh lebih tinggi dibandingkan dengan Random Forest. Maka dari itu, model yang dipilih adalah Logistic Regression.

# Evaluasi

Dalam proses evaluasi, akan disajikan informasi mengenai model yang dipilih, yaitu Logistic Regression, beserta penjelasan yang lebih detail mengenai perbandingannya dengan Random Forest dalam kasus ini melalui:
- Akurasi kedua model
- MSE (Mean Squared Error)

Penjelasan lebih lanjut mengenai model yang dipilih (Logistic Regression)
- Bobot dan nilai bias dari model
- Confusion Matrix
- Visualisasi Heatmap Confusion Matrix

## Metrik #1: Akurasi

Dalam hasil diatas, akan disajikan ulang hasil berupa akurasi dari kedua model tersebut, dan perbandingan akurasinya.

Dalam hasil ini, terlihat bahwa akurasi dari model yang menggunakan Logistic Regression lebih tinggi daripada Random Forest. Maka dari itu, pemilihan model jatuh pada Logistic Regression.
"""

print("Akurasi model Logistic Regression: {}".format(model_logRes.score(X_test,y_test).round(3)))
print("Akurasi model Random Forest\t: {}".format(model_RF.score(X_test,y_test).round(3)))

"""## Metrik #2: MSE

Melakukan pengecekan Mean Squared Error (MSE) pada metode Linear Regression dan Random Forest. Dalam Metrik ini, akan disajikan sebuah grafik yang merupakan hasil dari MSE dari perbandingan keduanya.
"""

#evaluasi menggunakan MSE

mse = pd.DataFrame(columns=['train', 'test'], index=['LogRes','RF'])
model_dict = {'LogRes': model_logRes, 'RF': model_RF}
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
mse

"""Plotting hasil MSE untuk melihat dengan lebih baik."""

#plotting MSE

import matplotlib.pyplot as plt

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""## Bobot dan nilai Bias Logistic Regression

Mencari weight/bobot dari masing-masing variabel yang ada dalam model Linear Regression. Pencarian ini dilakukan secara matematis untuk mengetahui nilai dari bobot tiap variabel, dan nilai bias dari sistem setelah dilakukan sejumlah N perulangan.
"""

#mencari weight/bobot dari masing-masing variabel yang ada dalam model

print("Nilai Bobot Tiap Variabel:\n{}\n\nNilai Bias: {}\n\nBanyaknya iterasi: {}".format(model_logRes.coef_[0], model_logRes.intercept_[0], model_logRes.n_iter_[0]))

"""## Confusion Matrix Logistic Regression

Membuat confusion matrix untuk mengetahui letak prediksi yang salah, maupun prediksi yang benar pada saat model melakukan prediksi.
"""

#membuat confusion matrix untuk mengetahui letak kesalahan pada prediksi model

cn_logRes = confusion_matrix(y_test,y_pred_logRes)
print("Confusion Matrix Logistic Regression:\n{}".format(cn_logRes))

"""## Heatmap visualisasi Confusion Matrix

Visualisasi data melalui heatmap untuk melihat lebih jelas distribusi dari hasil prediksi model.
"""

#heatmap plot menggunakan sns
sns.heatmap(cn_logRes, annot=True)