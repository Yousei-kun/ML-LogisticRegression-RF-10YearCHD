{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.9.1",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "metadata": {
      "interpreter": {
        "hash": "75fe66cc5c562c8b7ab53726264ba1dcd972787fdbff729afe5074f433741fc8"
      }
    },
    "interpreter": {
      "hash": "75fe66cc5c562c8b7ab53726264ba1dcd972787fdbff729afe5074f433741fc8"
    },
    "colab": {
      "name": "submission_ml_terapan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIyX2je0j0oc"
      },
      "source": [
        "# Identitas & Definisi Hasil Pekerjaan\n",
        "## Ivan Budianto\n",
        "\n",
        "### shinsuketenma0603@gmail.com\n",
        "### Submission Machine Learning Terapan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg_y1x8Qj0og"
      },
      "source": [
        "## Prediksi Penderita Penyakit Jantung Berdasarkan Statistik Kesehatan \n",
        "\n",
        "### Metode:\n",
        "- Logistic Regression\n",
        "- Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQLxzl-Tj0oh"
      },
      "source": [
        "Melakukan import library yang dibutuhkan (Pandas, Sci-Kit Learn, Seaborn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fGm6Sh2Oj0oh"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTc80IQzj0oi"
      },
      "source": [
        "# Pre-Processing\n",
        "\n",
        "## Berikut adalah langkah-langkah yang saya lakukan dalam proses preprocessing data:\n",
        "1. Memasukkan dataset kedalam dataframe dari file csv\n",
        "2. Menandai *numerical features* dari data untuk mempermudah proses scaling menggunakan standard scaler\n",
        "3. Melakukan drop di kolom education, karena kolom tersebut memiliki bobot yang kecil pada hasil akhir data, dan membuat fokus model berkurang.\n",
        "4. Mengisi missing value dengan median. Missing value akan membuat data tersebut tidak dapat digunakan, dan sangat sayang untuk membuang informasi penting pada banyak row hanya karena 1-2 missing value, maka dilakukan pengisian missing value. Pengisian data dengan menggunakan median akan membantu \"menetralkan\" data yang hilang, karena pengisian median tidak akan menggeser atau menambah varians dari data.\n",
        "5. Melakukan pemisahan antara dataset latihan (train) dan \n",
        "dataset test (test) dengan pembagian:\n",
        "  - 75% dataset latihan (train set)\n",
        "  - 25% dataset pengujian (test set)\n",
        "6. Scaling dengan Standard Scaler sklearn. Penggunaan Standard Scaler akan membuat fitur numerik dari data dapat diproses dengan lebih mudah oleh mesin untuk modelling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO3oJqYWj0oj"
      },
      "source": [
        "## Memasukkan dataset & menandai num features\n",
        "Memasukkan dataset kedalam dataframe dari file csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "ROH0Pl00j0oj",
        "outputId": "5eefde31-3c62-4af7-8fe7-60bf6d428454"
      },
      "source": [
        "#memasukkan dataset kedalam dataframe\n",
        "\n",
        "df = pd.read_csv('framingham.csv')\n",
        "numerical_features = ['cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>currentSmoker</th>\n",
              "      <th>cigsPerDay</th>\n",
              "      <th>BPMeds</th>\n",
              "      <th>prevalentStroke</th>\n",
              "      <th>prevalentHyp</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>totChol</th>\n",
              "      <th>sysBP</th>\n",
              "      <th>diaBP</th>\n",
              "      <th>BMI</th>\n",
              "      <th>heartRate</th>\n",
              "      <th>glucose</th>\n",
              "      <th>TenYearCHD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>26.97</td>\n",
              "      <td>80.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>28.73</td>\n",
              "      <td>95.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>127.5</td>\n",
              "      <td>80.0</td>\n",
              "      <td>25.34</td>\n",
              "      <td>75.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>28.58</td>\n",
              "      <td>65.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>285.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>23.10</td>\n",
              "      <td>85.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4233</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>25.97</td>\n",
              "      <td>66.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4234</th>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>126.5</td>\n",
              "      <td>80.0</td>\n",
              "      <td>19.71</td>\n",
              "      <td>65.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4235</th>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>22.00</td>\n",
              "      <td>84.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4236</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>126.5</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.16</td>\n",
              "      <td>86.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4237</th>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>269.0</td>\n",
              "      <td>133.5</td>\n",
              "      <td>83.0</td>\n",
              "      <td>21.47</td>\n",
              "      <td>80.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4238 rows Ã— 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      male  age  education  ...  heartRate  glucose  TenYearCHD\n",
              "0        1   39        4.0  ...       80.0     77.0           0\n",
              "1        0   46        2.0  ...       95.0     76.0           0\n",
              "2        1   48        1.0  ...       75.0     70.0           0\n",
              "3        0   61        3.0  ...       65.0    103.0           1\n",
              "4        0   46        3.0  ...       85.0     85.0           0\n",
              "...    ...  ...        ...  ...        ...      ...         ...\n",
              "4233     1   50        1.0  ...       66.0     86.0           1\n",
              "4234     1   51        3.0  ...       65.0     68.0           0\n",
              "4235     0   48        2.0  ...       84.0     86.0           0\n",
              "4236     0   44        1.0  ...       86.0      NaN           0\n",
              "4237     0   52        2.0  ...       80.0    107.0           0\n",
              "\n",
              "[4238 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD7UBbfHj0ok"
      },
      "source": [
        "## Drop column 'education'\n",
        "Melakukan drop di kolom education, karena kolom tersebut memiliki bobot yang kecil pada hasil akhir data, dan membuat fokus model berkurang."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V3azP_ZCj0ol"
      },
      "source": [
        "#menghapus kolom education\n",
        "\n",
        "df = df.drop('education',axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5WxauHrj0om"
      },
      "source": [
        "## Mengecek nilai NaN (1)\n",
        "Melakukan pengecekan pada setiap kolom dalam dataset untuk mencari nilai kosong (NaN)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0HBlJ2Mj0om",
        "outputId": "d16dd1bd-0e92-4167-c52c-8e091375abbf"
      },
      "source": [
        "#NaN check\n",
        "\n",
        "for i in df.columns:\n",
        "    print (i+\": \"+str(df[i].isna().sum()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "male: 0\n",
            "age: 0\n",
            "currentSmoker: 0\n",
            "cigsPerDay: 29\n",
            "BPMeds: 53\n",
            "prevalentStroke: 0\n",
            "prevalentHyp: 0\n",
            "diabetes: 0\n",
            "totChol: 50\n",
            "sysBP: 0\n",
            "diaBP: 0\n",
            "BMI: 19\n",
            "heartRate: 1\n",
            "glucose: 388\n",
            "TenYearCHD: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKyNcNF-j0on"
      },
      "source": [
        "## Mengisi missing value\n",
        "Mengisi missing value dengan median. Missing value akan membuat data tersebut tidak dapat digunakan, dan sangat sayang untuk membuang informasi penting pada banyak row hanya karena 1-2 missing value, maka dilakukan pengisian missing value. Pengisian data dengan menggunakan median akan membantu \"menetralkan\" data yang hilang, karena pengisian median tidak akan menggeser atau menambah varians dari data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qT-6NlCoj0op"
      },
      "source": [
        "#Mengisi nilai kosong pada dataset dengan median dari kolom tersebut\n",
        "\n",
        "df['cigsPerDay'] = df['cigsPerDay'].fillna(df['cigsPerDay'].median())\n",
        "df['BPMeds'] = df['BPMeds'].fillna(df['BPMeds'].median())\n",
        "df['totChol'] = df['totChol'].fillna(df['totChol'].median())\n",
        "df['BMI'] = df['BMI'].fillna(df['BMI'].median())\n",
        "df['glucose'] = df['glucose'].fillna(df['glucose'].median())\n",
        "df['heartRate'] = df['heartRate'].fillna(df['heartRate'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azfM0Fmzj0op"
      },
      "source": [
        "## Mengecek nilai NaN (2)\n",
        "Melakukan pengecekan kembali pada setiap kolom dalam dataset untuk mencari nilai kosong (NaN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-SGFNoHj0oq",
        "outputId": "f6094cef-aa4f-4586-aeef-2460a02ce279"
      },
      "source": [
        "#melakukan pengecekan pada setiap kolom dalam dataset untuk mencari nilai kosong (NaN) setelah dilakukan preprocessing\n",
        "\n",
        "for i in df.columns:\n",
        "    print (i+\": \"+str(df[i].isna().sum()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "male: 0\n",
            "age: 0\n",
            "currentSmoker: 0\n",
            "cigsPerDay: 0\n",
            "BPMeds: 0\n",
            "prevalentStroke: 0\n",
            "prevalentHyp: 0\n",
            "diabetes: 0\n",
            "totChol: 0\n",
            "sysBP: 0\n",
            "diaBP: 0\n",
            "BMI: 0\n",
            "heartRate: 0\n",
            "glucose: 0\n",
            "TenYearCHD: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "HRjVGx5Pj0oq",
        "outputId": "f5c1b31b-f763-4dd0-850b-9a8e7293e7ae"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male</th>\n",
              "      <th>age</th>\n",
              "      <th>currentSmoker</th>\n",
              "      <th>cigsPerDay</th>\n",
              "      <th>BPMeds</th>\n",
              "      <th>prevalentStroke</th>\n",
              "      <th>prevalentHyp</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>totChol</th>\n",
              "      <th>sysBP</th>\n",
              "      <th>diaBP</th>\n",
              "      <th>BMI</th>\n",
              "      <th>heartRate</th>\n",
              "      <th>glucose</th>\n",
              "      <th>TenYearCHD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "      <td>4238.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.429212</td>\n",
              "      <td>49.584946</td>\n",
              "      <td>0.494101</td>\n",
              "      <td>8.941482</td>\n",
              "      <td>0.029259</td>\n",
              "      <td>0.005899</td>\n",
              "      <td>0.310524</td>\n",
              "      <td>0.025720</td>\n",
              "      <td>236.689476</td>\n",
              "      <td>132.352407</td>\n",
              "      <td>82.893464</td>\n",
              "      <td>25.800205</td>\n",
              "      <td>75.878716</td>\n",
              "      <td>81.603587</td>\n",
              "      <td>0.151958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.495022</td>\n",
              "      <td>8.572160</td>\n",
              "      <td>0.500024</td>\n",
              "      <td>11.902399</td>\n",
              "      <td>0.168552</td>\n",
              "      <td>0.076587</td>\n",
              "      <td>0.462763</td>\n",
              "      <td>0.158316</td>\n",
              "      <td>44.327427</td>\n",
              "      <td>22.038097</td>\n",
              "      <td>11.910850</td>\n",
              "      <td>4.071041</td>\n",
              "      <td>12.025185</td>\n",
              "      <td>22.865246</td>\n",
              "      <td>0.359023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>15.540000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>23.080000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>234.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>25.400000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>89.875000</td>\n",
              "      <td>28.037500</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>696.000000</td>\n",
              "      <td>295.000000</td>\n",
              "      <td>142.500000</td>\n",
              "      <td>56.800000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>394.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              male          age  ...      glucose   TenYearCHD\n",
              "count  4238.000000  4238.000000  ...  4238.000000  4238.000000\n",
              "mean      0.429212    49.584946  ...    81.603587     0.151958\n",
              "std       0.495022     8.572160  ...    22.865246     0.359023\n",
              "min       0.000000    32.000000  ...    40.000000     0.000000\n",
              "25%       0.000000    42.000000  ...    72.000000     0.000000\n",
              "50%       0.000000    49.000000  ...    78.000000     0.000000\n",
              "75%       1.000000    56.000000  ...    85.000000     0.000000\n",
              "max       1.000000    70.000000  ...   394.000000     1.000000\n",
              "\n",
              "[8 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbL6Ihggj0oq"
      },
      "source": [
        "## Mendefinisikan X dan y\n",
        "Mendefinisikan X dan y, dimana:\n",
        "- X merupakan data yang menjadi tolok ukur untuk prediksi (data dari dataset)\n",
        "- y merupakan hasil atau tujuan dari hasil prediksinya "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yUyj7NjXj0oq"
      },
      "source": [
        "#mendefinisikan x dan y\n",
        "\n",
        "X = df.drop('TenYearCHD',axis='columns')\n",
        "y = df['TenYearCHD']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOVCs5lJj0or"
      },
      "source": [
        "## Split train & test set, standard scaling.\n",
        "\n",
        "Melakukan pemisahkan antara dataset latihan (train) dan \n",
        "dataset test (test) dengan pembagian:\n",
        "- 75% dataset latihan (train set)\n",
        "- 25% dataset pengujian (test set)\n",
        "\n",
        "Lalu, dilanjutkan dengan melakukan standard scaling untuk data-data numerik.\n",
        "Scaling dilakukan dengan Standard Scaler sklearn. Penggunaan Standard Scaler akan membuat fitur numerik dari data dapat diproses dengan lebih mudah oleh mesin untuk modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZdhM3H5j0or",
        "outputId": "71f65c6d-818a-45af-85c9-d7a60b95961e"
      },
      "source": [
        "# pemisahan dataset, dan scaling.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
        "\n",
        "scaler_train = StandardScaler()\n",
        "scaler_train.fit(X_train[numerical_features])\n",
        "X_train[numerical_features] = scaler_train.transform(X_train.loc[:, numerical_features])\n",
        "\n",
        "scaler_test = StandardScaler()\n",
        "scaler_test.fit(X_test[numerical_features])\n",
        "X_test[numerical_features] = scaler_train.transform(X_test.loc[:, numerical_features])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAr_mrAQmFG-"
      },
      "source": [
        "# Modelling\n",
        "\n",
        "Pembuatan model menggunakan 2 metode, yaitu:\n",
        "- Logistic Regression<br>\n",
        "Regresi logistik (kadang disebut model logistik atau model logit), dalam statistika digunakan untuk prediksi probabilitas kejadian suatu peristiwa dengan mencocokkan data pada fungsi logit kurva logistik. Metode ini merupakan model linier umum yang digunakan untuk regresi binomial. \n",
        "\n",
        "- Random Forest<br>\n",
        "Metode Random Forest  merupakan salah satu metode dalam Decision Tree. Decision Tree atau pohon pengambil keputusan adalah sebuah diagram alir yang berbentuk seperti pohon yang memiliki sebuah root node yang digunakan untuk mengumpulkan data, Sebuah inner node yang berada pada root node yang berisi tentang pertanyaan tentang data dan  sebuah leaf node yang digunakan untuk memecahkan masalah serta membuat keputusan.\n",
        "\n",
        "Penggunaan Model<br>\n",
        "Berdasarkan testing tersebut, maka dapat dilihat bahwa akurasi dari model Logistic Regression memiliki akurasi yang jauh lebih tinggi dibandingkan dengan Random Forest. Maka dari itu, model yang dipilih adalah Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzJd40GXj0or"
      },
      "source": [
        "## Mendefinisikan model & parameter yang digunakan\n",
        "Mendefinisikan model, dan metode yang digunakan, yaitu Logistic Regression & Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rCgaZMmrj0or"
      },
      "source": [
        "#mendefinisikan model dan metode \n",
        "model_logRes = LogisticRegression(max_iter=1000)\n",
        "model_RF = RandomForestRegressor(n_estimators=1000, max_depth=16, random_state=55, n_jobs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv1CINXQmhwq"
      },
      "source": [
        "## Melakukan proses training pada kedua model\n",
        "Melakukan proses training (fitting) pada kedua model menggunakan dataset yang sama, yaitu dataset training. Keduanya menggunakan syntax yang sama, yaitu fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBJl5K9imjMr",
        "outputId": "4e5fdf63-012b-4c38-b556-55d93750d064"
      },
      "source": [
        "#melakukan fitting model menggunakan dataset train pada 2 model\n",
        "model_logRes.fit(X_train,y_train)\n",
        "model_RF.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=16, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=1000, n_jobs=1, oob_score=False,\n",
              "                      random_state=55, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HXHfl7cj0os"
      },
      "source": [
        "## Proses testing model\n",
        "Melakukan testing pada test set berupa prediksi data pada dataset test, lalu menampilkan hasilnya berupa akurasi model untuk menentukan penggunaan model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm7Unlwoj0os",
        "outputId": "221c90f0-5b45-4ec4-8a8b-b694734f094e"
      },
      "source": [
        "#melakukan prediksi data pada dataset test, lalu menampilkan hasilnya\n",
        "\n",
        "y_pred_logRes = model_logRes.predict(X_test)\n",
        "y_pred_RF = model_RF.predict(X_test)\n",
        "\n",
        "print(\"Akurasi model Logistic Regression: {}\".format(model_logRes.score(X_test,y_test).round(3)))\n",
        "print(\"Akurasi model Random Forest\\t: {}\".format(model_RF.score(X_test,y_test).round(3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi model Logistic Regression: 0.866\n",
            "Akurasi model Random Forest\t: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hBf3kpvnauu"
      },
      "source": [
        "## Hasil model test\n",
        "Berdasarkan testing tersebut, maka dapat dilihat bahwa akurasi dari model Logistic Regression memiliki akurasi yang jauh lebih tinggi dibandingkan dengan Random Forest. Maka dari itu, model yang dipilih adalah Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXvJeE3Tj0os"
      },
      "source": [
        "# Evaluasi\n",
        "\n",
        "Dalam proses evaluasi, akan disajikan informasi mengenai model yang dipilih, yaitu Logistic Regression, beserta penjelasan yang lebih detail mengenai perbandingannya dengan Random Forest dalam kasus ini melalui:\n",
        "- Akurasi kedua model\n",
        "- MSE (Mean Squared Error)\n",
        "\n",
        "Penjelasan lebih lanjut mengenai model yang dipilih (Logistic Regression)\n",
        "- Bobot dan nilai bias dari model\n",
        "- Confusion Matrix\n",
        "- Visualisasi Heatmap Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVoAGwarojTK"
      },
      "source": [
        "## Metrik #1: Akurasi\n",
        "\n",
        "Dalam hasil diatas, akan disajikan ulang hasil berupa akurasi dari kedua model tersebut, dan perbandingan akurasinya.\n",
        "\n",
        "Dalam hasil ini, terlihat bahwa akurasi dari model yang menggunakan Logistic Regression lebih tinggi daripada Random Forest. Maka dari itu, pemilihan model jatuh pada Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qblfuKwyojm6",
        "outputId": "947cfd8c-f1ed-4653-c1c6-881f4442525f"
      },
      "source": [
        "print(\"Akurasi model Logistic Regression: {}\".format(model_logRes.score(X_test,y_test).round(3)))\n",
        "print(\"Akurasi model Random Forest\\t: {}\".format(model_RF.score(X_test,y_test).round(3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi model Logistic Regression: 0.866\n",
            "Akurasi model Random Forest\t: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKwo_g5wj0ou"
      },
      "source": [
        "## Metrik #2: MSE\n",
        "\n",
        "Melakukan pengecekan Mean Squared Error (MSE) pada metode Linear Regression dan Random Forest. Dalam Metrik ini, akan disajikan sebuah grafik yang merupakan hasil dari MSE dari perbandingan keduanya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "QBirNF7Nj0ou",
        "outputId": "d68cbad0-f01b-43f8-e7e6-8c6b25bf6863"
      },
      "source": [
        "#evaluasi menggunakan MSE\n",
        "\n",
        "mse = pd.DataFrame(columns=['train', 'test'], index=['LogRes','RF'])\n",
        "model_dict = {'LogRes': model_logRes, 'RF': model_RF}\n",
        "for name, model in model_dict.items():\n",
        "    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 \n",
        "    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3\n",
        "mse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogRes</th>\n",
              "      <td>0.000147262</td>\n",
              "      <td>0.000133962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>2.60137e-05</td>\n",
              "      <td>0.000119166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              train         test\n",
              "LogRes  0.000147262  0.000133962\n",
              "RF      2.60137e-05  0.000119166"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-V_64j-j0ou"
      },
      "source": [
        "Plotting hasil MSE untuk melihat dengan lebih baik."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "U0DIvT4hj0ou",
        "outputId": "0f11519f-8cec-4ac9-fb3f-dd3938d0b171"
      },
      "source": [
        "#plotting MSE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)\n",
        "ax.grid(zorder=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ3klEQVR4nO3df5BV5X3H8fdXISwLDDBLtBUS2dQkxWACxvgjMZNrjRHQOnGacWJqpumkJZOQX6U64MSkJn8xtXUIMxmJNdS0GVtNMtZMwAZtueooxAIhqOGnkQwrEzU0MIBgxTz94x7MZZ/dZXe9yzm7vF8zO3Pv+fGcz925ez/7nHP3bqSUkCSp2WllB5AkVY/lIEnKWA6SpIzlIEnKWA6SpMyosgO0yqRJk9I555xTdox+OXToEOPGjSs7Rr8Mp6wwvPKadegMp7xlZ92wYcNvUkpv7r58xJTDmWeeyfr168uO0S/1ep1arVZ2jH4ZTllheOU169AZTnnLzhoRv+ppuaeVJEkZy0GSlLEcJEmZEXPNQZIG6tVXX6Wrq4sjR46UlmHixIls2bJlyI/T1tbGtGnTGD16dL+2txwknbK6urqYMGEC06dPJyJKyXDgwAEmTJgwpMdIKbF37166urro7Ozs1z6eVpJ0yjpy5AgdHR2lFcPJEhF0dHQMaIZkOUg6pY30YjhmoI/TcpAkZbzmIEmF6YtXtnS8XUuu6nP9vn37WLFiBQsXLhzQuPPmzeOee+5h0qRJbyRen5w5SFJJ9u3bx1133ZUtP3r0aJ/7rVq1akiLAZw5SFJpFi9ezHPPPcesWbMYPXo0bW1tTJ48ma1bt7J9+3Y++tGPsnv3bo4cOcKXvvQl5s+fD8D06dNZv349Bw8eZO7cuVx66aU88cQTTJ06lQceeICxY8e+4WzOHCSpJEuWLKGzs5NNmzZx2223sXHjRr75zW+yfft2AFasWMGGDRtYv349y5YtY+/evdkYO3bsYMGCBTzzzDNMmjSJH/7why3J5sxBkiriwgsvPO7vEJYtW8b9998PwO7du9mxYwcdHR3H7dPZ2cmsWbMAeO9738uuXbtaksVykKSKaP7o7nq9zsMPP8zatWtpb2+nVqv1+HcKY8aMef326aefzuHDh1uSxdNKklSSCRMmcPDgwR7X7d+/n8mTJ9Pe3s7WrVtZt27dSc3mzEGSCid662mrdXR0cNFFFzFz5kzGjh3LmWee+fq6OXPmsHz5cmbMmME73/lOLr744pOazXKQpBKtWLGix89WGjNmDA8++GCP+xy7rjBlyhSefvrp15ffeOONLcvlaSVJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlfCurJB1z68QWj7e/z9WD/chugKVLlzJ//nza29sHm65PzhwkqSS9fWR3fyxdupSXX365xYl+z5mDJJWk+SO7r7jiCs444wzuu+8+XnnlFa699lq+/vWvc+jQIa677jq6urp47bXX+OpXv8oLL7zAnj17uOyyy5gyZQpr1qxpebYRUw7brv9166eEQ6QGUC83Q3/VYNhkheGVtwZmbbUTnMapmiVLlrB582Y2bdrE6tWr+cEPfsCTTz5JSolrrrmGRx99lJdeeomzzjqLlSsb/6Vu//79TJw4kdtvv501a9YwZcqUIcnmaSVJqoDVq1ezevVqZs+ezfnnn8/WrVvZsWMH5513Hg899BCLFi3iscceY+LEk/NL8IiZOUjScJZS4uabb+Yzn/lMtm7jxo2sWrWKW265hcsvv5yvfe1rQ57HmYMklaT5I7uvvPJKVqxY8fr9559/nhdffJE9e/bQ3t7ODTfcwE033cTGjRtf3/fAgQNDls2ZgyQdc5KvWTR/ZPfcuXP5xCc+wSWXXALA+PHj+d73vsfOnTu56aabOO200xg9ejR33HEHAPPnz2fOnDmcddZZQ3JBOlJKLR+0FLdOHCEPRNKgFS/u9XqdWq12ws23bNnCjBkzhjhU3w4cONDjR3YPhZ4eb0RsSCld0H1bTytJkjKWgyQpYzlIOqWNmFPrJzDQx2k5SDpltbW1sXfv3hFfECkl9u7dS1tbW7/38d1Kkk5Z06ZNo6uri5deeqm0DEeOHBnQi/ZgtbW1MW3atH5vbzlIOmWNHj2azs7OUjPU63Vmz55daoaeeFpJkpSxHCRJGctBkpSxHCRJGctBkpSxHCRJGctBkpSxHCRJGctBkpSxHCRJGctBkpSxHCRJmVI/eC8iXgOeKnI8B3wypbQvIqYDW4BtTZtfmFL6v5MeUpJOQWXPHA6nlGallGYC/wssaFr3bLHu2JfFIEknSdnl0GwtMLXsEJKkivw/h4g4Hbgc+E7T4j+KiE3F7cdTSgt62G8+MB/g7EU/HvKcZbp7zrhSjnvw4EHGjx9fyrEHYzjlNesQqNeBRt56cbvqqpq17HIYWxTAVBrXGB5qWvdsSmlWXzunlO4E7gSYvnjliP4/f7VarZTj1uv10o49GMMpr1mHznDKW9WsZZ9WOlwUwNlAcPw1B0lSScouBwBSSi8DXwT+NiLKns1I0imvEuUAkFL6GbAZuL7sLJJ0qiv1t/SU0vhu9/+06e7MkxxHklSozMxBklQdloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyloMkKWM5SJIyo8oO0Cpj7l/Itm3byo7RL/V6nVqtVnYMSeqVMwdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUiZSSmVnaI1bJ46QByJp2Lp1/4B3qdfr1Gq11mfpp4jYkFK6oPtyZw6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpIzlIEnKWA6SpMwJyyEiDr7Rg0RELSL2R8SmiNgaEf/wRseUJA2dkzlzeCylNAuYDVwdER84iceWJA3AoMohImZFxLqI2BwR90fE5GL5+4plmyLitoh4uvu+KaXDwCZgarHPRyJibURsjIjvR8T4YvmSiPhFMZ4zDUk6iUYNcr9/Ab6QUnokIr4B/B3wZeCfgb9OKa2NiCU97VgUyduBRyNiCnAL8OGU0qGIWAQsjIhvAdcCf5xSShExqZex5gPzAc5e9ONBPhRJapHFKwe3338Ocj/g7jnjBr1vXwZcDhExEZiUUnqkWPRd4PvFC/iElNLaYvk9wNVNu34wIn5OoxiWppR+HRFXA+cCj0cEwJuAtcB+4AjwnYj4MdDjK39K6U7gToDpi1emgT4WSRruarXakIw72JnDYDyWUro6IjqBdRFxHxDAQyml67tvHBEXApcDHwM+D/zJScwqSae0AV9zSCntB34bER8sFn0SeCSltA84EBEXFcs/3sv+zwFLgEXAOuADEXEOQESMi4h3FNcdJqaUVgF/A7xnoDklSYPXn5lDe0R0Nd2/HfgLYHlEtAO/BP6yWPdp4J8i4nfAIzROD/VkOXAjMA74FPBvETGmWHcLcAB4ICLaaMwuFvb7EUmS3rATlkNKqbfZxcU9LHsmpfRugIhYDKwvxqgD9aYxD1O8WwnYBbyvh7EuPFE2SdLQaPU1h6si4uZi3F/RmBVIkoaZlpZDSule4N5WjilJOvn8bCVJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlLAdJUsZykCRlRpUdoFXG3L+Qbdu2lR2jX+r1OrVarewY/TKcssLwymvWoTOc8lY1qzMHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSKlVHaGloiIA8C2snP00xTgN2WH6KfhlBWGV16zDp3hlLfsrGenlN7cfeGoMpIMkW0ppQvKDtEfEbHerENjOOU169AZTnmrmtXTSpKkjOUgScqMpHK4s+wAA2DWoTOc8pp16AynvJXMOmIuSEuSWmckzRwkSS1iOUiSciml0r6AOTT+NmEnsLiH9WOAe4v1PwWmN627uVi+DbjyRGMCncUYO4sx33SiY1Qw60LgF8Bm4L9ovD+5st/bpvV/BiTggipnBa4rvr/PAPdUNSvwVmAN8LPiuTCvAlk/XyxLwJSm5QEsK9ZtBs6vyHO2t7x/XuR8CngCeE9Vszatfx9wFPhYb9/bwXy1bKABHxhOB54F3ga8Cfg5cG63bT4HLC9ufxy4t7h9brH9mOIH6NlivF7HBO4DPl7cXg58tq9jVDTrZUB7cfuzPWWtUt7i/gTgUWAdPZRDVbICb6fxYju5uH9GhbPe2XT7XGBXBbLOBqYDuzj+xXYe8CCNkrgY+GlFnrO95X1/03Ngbk95q5K1Kct/A6sYQeVwCfCTpvs3Azd32+YnwCXF7VE0/oowum97bLvexiz2+Q0wqvuxeztGFbN2O95s4PEqf2+L+0uBq4A6PZdDJbICfw/81TB5zn4bWNS0/Ikys3YbcxfHv9h+G7i+6f424A+rmrfbusnA81XOCnwZWADcTYvLocxrDlOB3U33u4plPW6TUjoK7Ac6+ti3t+UdwL5ijO7H6u0YVcza7NM0fiPrSSXyRsT5wFtSSit7yVmZrMA7gHdExOMRsS4i5lQ4663ADRHRReM3xi+UnLUv/d2nKnmb9fYzVomsETEVuBa44wSPY1BG0sdnnDIi4gbgAuBDZWfpTUScBtwOfKrkKP01isappRowDXg0Is5LKe0rNVXPrgfuTin9Y0RcAvxrRMxMKf2u7GAjRURcRqMcLi07Sx+W0phB/i4iWj54meXwPPCWpvvTimU9bdMVEaOAicDeE+zb0/K9wKSIGFW0ePP2vR2jilmJiA8DXwE+lFJ6hZ5VIe8EYCZQL564fwD8KCKuSSmtr1hWaPym9tOU0qvAcxGxnUZZ/E8Fs36axsVLUkprI6KNxoe3vVhS1r70J0eV8hIR7wbuAuamlLq/FlQp6wXAvxc/X1OAeRFxNKX0HyfYr39aeY5qIF80iumXNC7KHLsA865u2yzg+Is69xW338XxF3V+SePCTK9jAt/n+It7n+vrGBXNOpvGRau3D4fvbbfj1en5mkMlstJ4sf1ucXsKjSl+R0WzPgh8qrg9A9hDfp3spGZtGnMXx19zuIrjL0g/WYXnbB9530rjnUHvr8rPV29Zu627m5FyQbp4QPOA7TRe8L5SLPsGcE1xu634AdkJPAm8rWnfrxT7baPR8L2OWSx/WzHGzmLMMSc6RgWzPgy8AGwqvn5U5e9ttzx1en8ra+lZabx43U7jraxPUbwoVzTrucDjNF5ANgEfqUDWL9KYfR2lUVZ3NX1fv1Vs/1Rvz4EK5b0L+C2//xlbX9Ws3fLcTYvLwY/PkCRl/AtpSVLGcpAkZSwHSVLGcpAkZSwHSVLGcpAkZSwHSVLm/wEOlm11p8PLiAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNOBaqQHj0os"
      },
      "source": [
        "## Bobot dan nilai Bias Logistic Regression\n",
        "\n",
        "Mencari weight/bobot dari masing-masing variabel yang ada dalam model Linear Regression. Pencarian ini dilakukan secara matematis untuk mengetahui nilai dari bobot tiap variabel, dan nilai bias dari sistem setelah dilakukan sejumlah N perulangan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znmMHoUOj0os",
        "outputId": "50583c5d-f057-4c06-e2d2-925cb3f85ef0"
      },
      "source": [
        "#mencari weight/bobot dari masing-masing variabel yang ada dalam model\n",
        "\n",
        "print(\"Nilai Bobot Tiap Variabel:\\n{}\\n\\nNilai Bias: {}\\n\\nBanyaknya iterasi: {}\".format(model_logRes.coef_[0], model_logRes.intercept_[0], model_logRes.n_iter_[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nilai Bobot Tiap Variabel:\n",
            "[ 0.43435132  0.06444877 -0.07364571  0.29695524  0.21615732  0.63344068\n",
            "  0.16974621  0.0995346   0.0347053   0.28958578  0.05877288 -0.04884005\n",
            " -0.07666783  0.18943376]\n",
            "\n",
            "Nilai Bias: -5.351232848907937\n",
            "\n",
            "Banyaknya iterasi: 292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCTNj-_tj0ot"
      },
      "source": [
        "## Confusion Matrix Logistic Regression\n",
        "\n",
        "Membuat confusion matrix untuk mengetahui letak prediksi yang salah, maupun prediksi yang benar pada saat model melakukan prediksi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfWoINofj0ot",
        "outputId": "07fbb450-9b67-4470-8c57-5e0cfd85c2a5"
      },
      "source": [
        "#membuat confusion matrix untuk mengetahui letak kesalahan pada prediksi model\n",
        "\n",
        "cn_logRes = confusion_matrix(y_test,y_pred_logRes)\n",
        "print(\"Confusion Matrix Logistic Regression:\\n{}\".format(cn_logRes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix Logistic Regression:\n",
            "[[901   7]\n",
            " [135  17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_an_nx-Xj0ot"
      },
      "source": [
        "## Heatmap visualisasi Confusion Matrix\n",
        "\n",
        "Visualisasi data melalui heatmap untuk melihat lebih jelas distribusi dari hasil prediksi model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "TfoH-I_qj0ot",
        "outputId": "3412bf9c-c265-44f4-917f-ccebbf0319c4"
      },
      "source": [
        "#heatmap plot menggunakan sns\n",
        "sns.heatmap(cn_logRes, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f23dffc7310>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}